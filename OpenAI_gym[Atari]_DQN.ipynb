{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPnKKkF+3fkwkVbP/y2fL4D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Loki-33/RL-Algos/blob/main/OpenAI_gym%5BAtari%5D_DQN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HpTbwA90zFp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from collections import deque\n",
        "import random\n",
        "import gym\n",
        "import cv2\n",
        "from gym.wrappers import AtariPreprocessing, FrameStack"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_frame(frame):\n",
        "  gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
        "  resized = cv2.resize(gray, (84,84), interpolation=cv2.INTER_AREA) #INTER_AREA->preserves structure and motion\n",
        "  return resized\n",
        "\n",
        "def stack_frames(stacked_frames, frames, is_new_episode):\n",
        "  frame = preprocess_frame(frames)\n",
        "  if is_new_episode:\n",
        "    stacked_frames = deque([frame]*4, maxlen=4)\n",
        "  else:\n",
        "    stacked_frames.append(frame)\n",
        "  return np.stack(stacked_frames, axis=0), stacked_frames"
      ],
      "metadata": {
        "id": "cJWxd7Y_1V7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we donot need to do the above we can use gym build in wrappers"
      ],
      "metadata": {
        "id": "XWNK5faJ2-pv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gym[atari,accept-rom-license]"
      ],
      "metadata": {
        "id": "8dVX2a6yC0zY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make(\"BreakoutNoFrameskip-v4\", render_mode='rgb_array')\n",
        "env = AtariPreprocessing(env, frame_skip=1, grayscale_obs=True, scale_obs=False)\n",
        "env = FrameStack(env, num_stack=4)"
      ],
      "metadata": {
        "id": "Qmgt6QP-3N-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state, _ = env.reset()"
      ],
      "metadata": {
        "id": "mMdHf-ggDJ18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state"
      ],
      "metadata": {
        "id": "ndigCBVqDJuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(env.action_space)\n",
        "'''\n",
        "0: DO NOTHING\n",
        "1: FIRE\n",
        "2: MOVE RIGHT\n",
        "3: MOVE LEFT\n",
        "'''"
      ],
      "metadata": {
        "id": "3LQ6s0i5F1zg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "pDi0gopRDJoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(16,4))\n",
        "for i in range(4):\n",
        "  fig.add_subplot(1,4,i+1)\n",
        "  plt.imshow(state[i], cmap=\"gray\")\n",
        "  plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "GUrGlzokDJh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DQNetwork(nn.Module):\n",
        "  def __init__(self, action_dim):\n",
        "    super(DQNetwork, self).__init__()\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=4, out_channels=32, kernel_size=8, stride=4),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(7*7*64, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, action_dim)\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    return self.net(x)"
      ],
      "metadata": {
        "id": "dgyprmO2DJap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "Z4VC2jR8HoRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "id": "ffyho9LtNfRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "action_dim = 4\n",
        "q_net = DQNetwork(action_dim).to(device)\n",
        "target_net = DQNetwork(action_dim).to(device)\n",
        "target_net.load_state_dict(q_net.state_dict())"
      ],
      "metadata": {
        "id": "91aFSeSnDJSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gamma = 0.99\n",
        "epsilon = 1.0\n",
        "epsilon_decay = 0.995\n",
        "epsilon_min = 0.05\n",
        "lr = 1e-3\n",
        "batch_size = 32\n",
        "buffer_size = 1000\n",
        "target_update_freq = 20\n",
        "episodes = 500"
      ],
      "metadata": {
        "id": "1X5KT9AFDJI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(q_net.parameters(), lr=lr)\n",
        "loss_fn = nn.MSELoss().to(device)"
      ],
      "metadata": {
        "id": "fXOknrMOI9pp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "buffer = deque(maxlen=buffer_size)"
      ],
      "metadata": {
        "id": "Vd19LYesIiqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_rewards = []"
      ],
      "metadata": {
        "id": "mTyy_ktJCqma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ep in range(episodes):\n",
        "  state, _ = env.reset()\n",
        "  done = False\n",
        "  episode_reward = 0\n",
        "  while not done:\n",
        "    if random.random() < epsilon:\n",
        "      action = env.action_space.sample()\n",
        "    else:\n",
        "      with torch.no_grad():\n",
        "        state_tensor = torch.tensor(np.array(state), dtype=torch.float32, device=device).unsqueeze(0) / 255.0\n",
        "        q_values = q_net(state_tensor)\n",
        "        action = torch.argmax(q_values, dim=1).item()\n",
        "    next_state, reward, done, truncated, _ = env.step(action)\n",
        "    episode_reward += reward\n",
        "    buffer.append((state, action, reward, next_state, done))\n",
        "    state = next_state\n",
        "    reward = np.clip(reward, -1, 1)\n",
        "    if len(buffer) >= batch_size:\n",
        "      batch = random.sample(buffer, batch_size)\n",
        "      states, actions, rewards, next_states, dones = zip(*batch)\n",
        "\n",
        "      s = torch.tensor(np.array(states), dtype=torch.float32, device=device) / 255.0\n",
        "      a = torch.tensor(actions, dtype=torch.int64, device=device).unsqueeze(1)\n",
        "      r = torch.tensor(rewards, dtype=torch.float32, device=device).unsqueeze(1)\n",
        "      s2 = torch.tensor(np.array(next_states), dtype=torch.float32, device=device)/ 255.0\n",
        "      d = torch.tensor(dones, dtype=torch.float32, device=device).unsqueeze(1)\n",
        "\n",
        "      q_values = q_net(s).gather(1, a)\n",
        "\n",
        "      with torch.no_grad():\n",
        "        #double DQN\n",
        "        next_action = q_net(s2).max(1, keepdim=True)[1]\n",
        "        next_q_values = target_net(s2).gather(1, next_action)\n",
        "        target_q_values = r + gamma * next_q_values * (1 - d)\n",
        "\n",
        "      loss = loss_fn(q_values, target_q_values)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    if done or truncated:\n",
        "      break\n",
        "\n",
        "  epsilon = max(epsilon_min, epsilon * epsilon_decay)\n",
        "\n",
        "  if ep % target_update_freq == 0:\n",
        "    target_net.load_state_dict(q_net.state_dict())\n",
        "\n",
        "  all_rewards.append(episode_reward)\n",
        "\n",
        "  if ep%50 == 0:\n",
        "    avg_reward = np.mean(all_rewards[-50:])\n",
        "    print(f\"Episode {ep}, Reward: {episode_reward}, Avg(50): {avg_reward:.2f}, Epsilon: {epsilon:.3f}\")\n"
      ],
      "metadata": {
        "id": "ub7UQcWYH7zI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output"
      ],
      "metadata": {
        "id": "tCMo8KMeOQsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_frames(frame):\n",
        "  frame = frame[0]\n",
        "  plt.imshow(frame)\n",
        "  plt.axis(\"off\")\n",
        "  clear_output(wait=True)\n",
        "  display(plt.gcf())"
      ],
      "metadata": {
        "id": "qHovJAuCOcXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "done = False\n",
        "state, _ = env.reset()"
      ],
      "metadata": {
        "id": "-jJTlNEFJ-69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while not done:\n",
        "  frame = env.render()\n",
        "  plot_frames(frame)\n",
        "  time.sleep(0.01)\n",
        "  with torch.no_grad():\n",
        "    state_tensor = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0) / 255.0\n",
        "    q_values = q_net(state_tensor)\n",
        "    action = torch.argmax(q_values, dim=1).item()\n",
        "  next_state, reward, done, truncated, _ = env.step(action)\n",
        "  state = next_state\n",
        "env.close()"
      ],
      "metadata": {
        "id": "u4pNM7KJOEKY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}